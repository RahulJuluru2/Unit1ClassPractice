{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo_KNN_Scaling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulJuluru2/Unit1ClassPractice/blob/main/Demo_KNN_Scaling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pfsihlQZzYp"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAo1CaILZ4dh"
      },
      "source": [
        "## Learning Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o7j8P4uaGwF"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* Classify fruits data using KNN classifier\n",
        "* Visualize the predictions before and after scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbSKRbudra-i"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3k3JXdqUt2W"
      },
      "source": [
        "The dataset chosen for this  experiment is a handmade fruits dataset. The dataset contains 60 records. Each record represents the following details of fruits : \n",
        "\n",
        "*  Weight -   It is the mass of an object. With respect to this dataset, we have calculated the weights in grams \n",
        "\n",
        "* Sphericity -   is a measure of how closely the shape of an object approaches that of a mathematically perfect sphere.\n",
        "\n",
        "* Color -  Every fruit has a different color at different stages. You can encode the color to an integer value. For example\n",
        "\n",
        "     - Green as 20\n",
        "     - Greenish Yellow as 40\n",
        "     - Orange as 60\n",
        "     - Red as 80\n",
        "     - Reddish Yellow as 100\n",
        "\n",
        "*  Label -   We have considered two fruits for simplicity. They are Apple and Orange.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhA-4D7SrIpo"
      },
      "source": [
        "## Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lh0Ez4Tny-9"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4UW1kzWny_I"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRvlfkw5rV_Q",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"Demo_KNN_Scaling\" #name of the notebook\n",
        "Answer = \"Ungraded\"\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/fruits_weight_sphercity.csv\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    \n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"feedback_experiments_input\" : Comments, \"notebook\" : notebook}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aiml.iiith.talentsprint.com/notebook_submissions\")\n",
        "        # print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "      return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "    \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHmPVwT2agjw"
      },
      "source": [
        "## Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsGDWqxJp5Ga"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-gaNks8hNq0"
      },
      "source": [
        "fruits_data = pd.read_csv('fruits_weight_sphercity.csv')\n",
        "fruits_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6Rq_Scnp5GR"
      },
      "source": [
        "# Encode the labels and Color column\n",
        "fruits_data['Color'] = fruits_data['Color'].replace(['Green', 'Greenish yellow', 'Orange', 'Red','Reddish yellow'],[20, 40, 60, 80, 100])  \n",
        "fruits_data['labels'] = fruits_data['labels'].replace(['apple','orange'],[1, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUmLDvaDjd-r"
      },
      "source": [
        "fruits_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWx4jyJyOnWI"
      },
      "source": [
        "## Take the data samples for training after the interval of  3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3ri3w-P-Zei"
      },
      "source": [
        "# Consider only 20 samples for Train Set\n",
        "train = fruits_data[0:60:3] \n",
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPCwN68VbCe_"
      },
      "source": [
        "## Check the length of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAX-BtAVxdQ4"
      },
      "source": [
        "print(len(fruits_data))\n",
        "print(len(train))\n",
        "print(type(train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgpKiq0DKhwM"
      },
      "source": [
        "# Consider 5 samples for Test set after the interval of 10\n",
        "test = fruits_data[1:50:10] \n",
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwFkpHJQqDnT"
      },
      "source": [
        "print(len(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjWt42NlKxL-"
      },
      "source": [
        "# Features of training data and testing data  \n",
        "traindata = train.iloc[:, 1:4] \n",
        "testdata = test.iloc[:, 1:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQC0ScQsArE0"
      },
      "source": [
        "traindata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJDd0yE7cw4E"
      },
      "source": [
        "testdata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2qhRODXcAo0"
      },
      "source": [
        "traindata.shape, testdata.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4ujaf0XcEkL"
      },
      "source": [
        "## Apply KNN Classifier on the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxKqhCGwKwQC"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "k = 3\n",
        "neigh = KNeighborsClassifier(n_neighbors=k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfJ5q6DzK_e8"
      },
      "source": [
        "# Train or fit the model with the train data\n",
        "neigh.fit(traindata, train.labels)\n",
        "\n",
        "# Test the trained model\n",
        "predictions = neigh.predict(testdata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCTiZxd8LFF1"
      },
      "source": [
        "print(predictions, \"predictions\")\n",
        "print(test.labels.values, \"Actual_labels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4BS59QF0ET4"
      },
      "source": [
        "# Stack the test data with predictions (can be used for plotting)\n",
        "predicted_data = np.column_stack((testdata.iloc[:,:2], predictions))\n",
        "\n",
        "predicted_df = pd.DataFrame(predicted_data, columns = ['Weight','Sphericity', 'labels'])\n",
        "predicted_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztGh7SN8rRzp"
      },
      "source": [
        "## Plot the train, test and predictions before scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t3dPW2kuzJ5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import category_scatter\n",
        "\n",
        "def plotting(traindata, testdata, df_Pred):\n",
        "    \n",
        "  Oranges_train, Oranges_test = traindata[traindata.labels == 0], testdata[testdata.labels == 0] \n",
        "  Apples_train, Apples_test = traindata[traindata.labels == 1], testdata[testdata.labels == 1]\n",
        "\n",
        "  Oranges_pred = df_Pred[df_Pred.iloc[:,2] == 0]\n",
        "  Apples_pred = df_Pred[df_Pred.iloc[:,2] == 1]\n",
        "\n",
        "  Oranges_train.shape , Apples_train.shape, Oranges_test.shape, Apples_test.shape, Oranges_pred.shape, Apples_pred.shape\n",
        "\n",
        "  df1 = (pd.concat([Oranges_train, Oranges_test, Apples_train, Apples_test], axis=0, keys=('Oranges_train', 'Oranges_test', 'Apples_train', 'Apples_test'))\n",
        "          .swaplevel(0,1, axis=0))\n",
        "  df1 = df1.reset_index(level=1)\n",
        "  df2 = (pd.concat([Oranges_train, Oranges_pred, Apples_train, Apples_pred], axis=0, keys=('Oranges_train', 'Oranges_pred', 'Apples_train','Apples_pred'))\n",
        "          .swaplevel(0,1, axis=0))\n",
        "  df2 = df2.reset_index(level=1)\n",
        "\n",
        "  fig = category_scatter(x='Sphericity', y='Weight', label_col='level_1', \n",
        "                        data=df1, markers='*o*o', colors=('red', 'red', 'green', 'green'), markersize=50, legend_loc='upperleft')\n",
        "\n",
        "  fig = category_scatter(x='Sphericity', y='Weight', label_col='level_1', \n",
        "                        data=df2, markers='*o*o', colors=('red', 'red', 'green', 'green'), markersize=50, legend_loc='upperleft')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotting(traindata, testdata, predicted_df)"
      ],
      "metadata": {
        "id": "Sb6bz3agSoZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1388cKOqMgAY"
      },
      "source": [
        "## Scaling the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmsKSruAMj7W"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSUpcm4_M4Ow"
      },
      "source": [
        "# Data Before Scaling\n",
        "fruits_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z-DQzldMkAF"
      },
      "source": [
        "fruits_data[['Sphericity', 'Weight']] = scaler.fit_transform(fruits_data[['Sphericity', 'Weight']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrF6-wc1MkEx"
      },
      "source": [
        "# Data After Scaling \n",
        "fruits_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_9PtiXGjxaJ"
      },
      "source": [
        "### Take the data samples for training after the interval of  3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io_zmoo0NKja"
      },
      "source": [
        "train = fruits_data[0:60:3]\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrpDVtTPNKoV"
      },
      "source": [
        "test = fruits_data[1:50:10]\n",
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE81qX7qrs-t"
      },
      "source": [
        "print(len(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf3dyoEpcodM"
      },
      "source": [
        "### Apply KNN Classifier on the scaled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW-rVBrcNKtg"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "k = 3\n",
        "neigh = KNeighborsClassifier(n_neighbors=k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-RgMjIrNKx5"
      },
      "source": [
        "# Convert dataframe into array\n",
        "traindata = train.iloc[:,1:4] \n",
        "testdata = test.iloc[:,1:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YIr3MfkNK3H"
      },
      "source": [
        "# Train or fit the model with the train data\n",
        "neigh.fit(traindata, train.labels)\n",
        "\n",
        "# Test the trained model\n",
        "scaled_predictions = neigh.predict(testdata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUgvF3lGOEqj"
      },
      "source": [
        "print(scaled_predictions,\"predictions\") \n",
        "print(test.labels.values,\"labels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QAGcnQCOi55"
      },
      "source": [
        "predicted_data = np.column_stack((testdata.iloc[:,:2], scaled_predictions))\n",
        "\n",
        "df_Pred_scale = pd.DataFrame(predicted_data, columns = ['Weight','Sphericity', 'labels'])\n",
        "df_Pred_scale.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFPGoPPvsUjx"
      },
      "source": [
        "### Plot the train and test points after scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HTHOnxo_jDa"
      },
      "source": [
        "plotting(traindata, testdata, df_Pred_scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ4kyJhDdDq6"
      },
      "source": [
        "#  Please answer the questions below to complete the experiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pke4SQ5NgNFX"
      },
      "source": [
        "#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cTetkuegP7d"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFQw0ddId_Ej"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-CXztFuygSBG"
      },
      "source": [
        "#@title Run this cell to submit your notebook  { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id =return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}